// ==========================================================
// deep scan script windowï¼ˆperformance optimization versionï¼‰
// log record å‡å°‘ã€optimization operation DOMã€æ§åˆ¶å¹¶å‘æ•°
// ==========================================================

//console.log('ğŸš€ [DEBUG] deep scan script windowï¼ˆperformance optimization versionï¼‰start load ...');

// -------------------- variable å…¨å±€ --------------------
let scanConfig         = null;
let scanResults        = {};
let isScanRunning      = false;
let isPaused           = false;
let currentDepth       = 0;
let scannedUrls        = new Set();
let pendingUrls        = new Set();
let urlContentCache    = new Map();
let activeRequests     = 0;
let maxConcurrency     = 3; // ğŸš€ å‡å°‘å¹¶å‘æ•°
let requestTimeout     = 3000; // ğŸš€ timeout when å‡å°‘é—´

// log variable related - optimization version
let logEntries         = [];
let maxLogEntries      = 50; // ğŸš€ log record(s) å¤§å¹…å‡å°‘ç›®
let logBuffer          = [];
let logFlushTimer      = null;
const LOG_FLUSH_INTERVAL = 1000; // ğŸš€ 1 second refresh log batch

// selector instance
let apiFilter          = null;
let domainPhoneFilter  = null;
let filtersLoaded      = false;
let patternExtractor   = null;

// performance optimization variable related
let updateQueue        = [];
let isUpdating         = false;
let lastUpdateTime     = 0;
const UPDATE_THROTTLE  = 500; // ğŸš€ 500ms throttleï¼Œupdate å¤§å¹…å‡å°‘é¢‘ç‡
let pendingResults     = {};
let batchSize          = 20; // ğŸš€ process batch å¢åŠ å¤§å°
let updateTimer        = null;
let displayUpdateCount = 0;

// ğŸš€ memory variable related ç®¡ç†
let memoryCleanupTimer = null;
const MEMORY_CLEANUP_INTERVAL = 30000; // 30 seconds cleanup memory time(s) ä¸€

// -------------------- performance optimization function å·¥å…· --------------------

// ğŸš€ cleanup memory function
function performMemoryCleanup() {
    //console.log('ğŸ§¹ cleanup memory execute ...');
    
    // URL cleanup content cacheï¼Œ item(s) of åªä¿ç•™æœ€è¿‘30
    if (urlContentCache.size > 30) {
        const entries = Array.from(urlContentCache.entries());
        const toKeep = entries.slice(-30);
        urlContentCache.clear();
        toKeep.forEach(([key, value]) => urlContentCache.set(key, value));
        //console.log(`ğŸ§¹ URL cleanup cacheï¼Œä¿ç•™ ${toKeep.length}  item(s) record(s) ç›®`);
    }
    
    // cleanup log ç¼“å†²åŒº
    if (logBuffer && logBuffer.length > 0) {
        flushLogBuffer();
    }
    
    // force åƒåœ¾å›æ”¶ï¼ˆavailable ifï¼‰
    if (window.gc) {
        window.gc();
    }
}

// cleanup memory when å¯åŠ¨å®šå™¨
function startMemoryCleanup() {
    if (memoryCleanupTimer) {
        clearInterval(memoryCleanupTimer);
    }
    memoryCleanupTimer = setInterval(performMemoryCleanup, MEMORY_CLEANUP_INTERVAL);
}

// cleanup stop memory when å®šå™¨
function stopMemoryCleanup() {
    if (memoryCleanupTimer) {
        clearInterval(memoryCleanupTimer);
        memoryCleanupTimer = null;
    }
}

// ğŸš€ add optimization log function of - log record å¤§å¹…å‡å°‘
function addLogEntry(message, type = 'info') {
    // ğŸš€ log record off åªé”®ï¼Œinformation filter log æ‰å¤§éƒ¨åˆ†
    if (type === 'info' && (
        message.includes('scan æ­£åœ¨:') || 
        message.includes('success content get') ||
        message.includes('not found data æ–°') ||
        message.includes('skip content text é') ||
        message.includes('subdomain å…è®¸') ||
        message.includes('domain all å…è®¸') ||
        message.includes('found') ||
        message.includes('extracted to')
    )) {
        return; // skip information log of è¿™äº›é¢‘ç¹
    }
    
    if (!logEntries) {
        logEntries = [];
    }
    
    // add to ç¼“å†²åŒº
    if (!logBuffer) {
        logBuffer = [];
    }
    logBuffer.push({ message, type, time: new Date().toLocaleTimeString() });
    
    // refresh log batch
    if (!logFlushTimer) {
        logFlushTimer = setTimeout(() => {
            flushLogBuffer();
            logFlushTimer = null;
        }, LOG_FLUSH_INTERVAL);
    }
}

// refresh log batch ç¼“å†²åŒº
function flushLogBuffer() {
    if (!logBuffer || logBuffer.length === 0) return;
    
    // add content log array to å°†ç¼“å†²åŒºä¸»
    logEntries.push(...logBuffer);
    logBuffer = [];
    
    // quantity log limit record(s) ç›®
    if (logEntries.length > maxLogEntries) {
        logEntries = logEntries.slice(-maxLogEntries);
    }
    
    // update display
    updateLogDisplay();
}

// ğŸš€ optimization log function display of
function updateLogDisplay() {
    const logSection = document.getElementById('logSection');
    if (!logSection || !logEntries) return;
    
    // log display record(s) of åªæœ€è¿‘20
    const recentLogs = logEntries.slice(-20);
    
    // update check no yes éœ€è¦
    const currentLogCount = logSection.children.length;
    if (currentLogCount === recentLogs.length) {
        return;
    }
    
    // update optimization use requestAnimationFrameDOM
    requestAnimationFrame(() => {
        const fragment = document.createDocumentFragment();
        recentLogs.forEach(log => {
            const logEntry = document.createElement('div');
            logEntry.className = `log-entry ${log.type}`;
            logEntry.textContent = `[${log.time}] ${log.message}`;
            fragment.appendChild(logEntry);
        });
        
        logSection.innerHTML = '';
        logSection.appendChild(fragment);
        logSection.scrollTop = logSection.scrollHeight;
    });
}

// ğŸš€ update function throttle display of
function throttledUpdateDisplay() {
    const now = Date.now();
    if (now - lastUpdateTime < UPDATE_THROTTLE) {
        return;
    }
    
    lastUpdateTime = now;
    requestAnimationFrame(() => {
        displayResults();
    });
}

// -------------------- function å·¥å…· --------------------

function convertRelativeToAbsolute(relativePath) {
    try {
        const base = scanConfig?.baseUrl || window.location.origin;
        return new URL(relativePath, base).href;
    } catch {
        return relativePath;
    }
}

function resolveUrl(url, baseUrl) {
    try {
        if (!url) return null;
        
        if (url.startsWith('http://') || url.startsWith('https://')) {
            return url;
        }
        
        if (url.startsWith('//')) {
            return new URL(baseUrl).protocol + url;
        }
        
        return new URL(url, baseUrl).href;
    } catch (error) {
        return null;
    }
}

// -------------------- scan function main --------------------

// ğŸš€ scan optimization function of
async function startScan() {
    if (isScanRunning) {
        //console.log('running scan å·²åœ¨');
        return;
    }

    isScanRunning = true;
    isPaused = false;
    
    try {
        //console.log('ğŸš€ deep scan start ...');
        addLogEntry('ğŸš€ deep scan start', 'success');
        
        // ğŸš€ cleanup memory å¯åŠ¨
        startMemoryCleanup();
        
        updateButtonStates();
        
        // initialize configuration load and
        await loadScanConfig();
        await loadFilters();
        
        // URL collected åˆå§‹
        const initialUrls = await collectInitialUrls();
        
        if (initialUrls.length === 0) {
            addLogEntry('âš ï¸ URL scan to of has æ²¡æ‰¾å¯', 'warning');
            return;
        }
        
        addLogEntry(`ğŸ“‹ collected to ${initialUrls.length} URL scan item(s) åˆå§‹`, 'success');
        
        // start scan layer(s) åˆ†
        let currentUrls = initialUrls;
        
        for (let depth = 1; depth <= scanConfig.maxDepth && isScanRunning; depth++) {
            currentDepth = depth;
            //console.log(`ğŸ” start # ${depth} scan layer(s)ï¼ŒURL quantity: ${currentUrls.length}`);
            addLogEntry(`ğŸ” start # ${depth} scan layer(s)ï¼ŒURL quantity: ${currentUrls.length}`, 'success');
            
            // ğŸš€ scan optimization batch of
            const newUrls = await scanUrlBatchOptimized(currentUrls, depth);
            currentUrls = newUrls;
            
            //console.log(`âœ… # ${depth} scan complete layer(s)ï¼ŒURL found æ–°: ${currentUrls.length}  item(s)`);
            addLogEntry(`âœ… # ${depth} scan complete layer(s)ï¼ŒURL found æ–°: ${currentUrls.length}  item(s)`, 'success');
            
            // ğŸš€ update scan force display layer(s) after æ¯
            displayResults();
            
            if (currentUrls.length === 0) {
                break;
            }
        }
        
        await completeScan();
        
    } catch (error) {
        console.error('âŒ scan failed:', error);
        addLogEntry(`âŒ scan failed: ${error.message}`, 'error');
    } finally {
        isScanRunning = false;
        updateButtonStates();
        // ğŸš€ cleanup stop memory
        stopMemoryCleanup();
    }
}

// ğŸš€ scan optimization function batch of
async function scanUrlBatchOptimized(urls, depth) {
    const newUrls = new Set();
    const activeWorkers = new Set();
    let processedCount = 0;
    const totalUrls = urls.length;
    
    const processQueue = async () => {
        for (let i = 0; i < urls.length && isScanRunning && !isPaused; i++) {
            const url = urls[i];
            
            if (scannedUrls.has(url)) {
                processedCount++;
                continue;
            }
            
            scannedUrls.add(url);
            
            const workerPromise = (async () => {
                try {
                    // ğŸš€ scan log remove of é¢‘ç¹
                    const content = await fetchUrlContent(url);
                    
                    if (content) {
                        // data extracted
                        const extractedData = await extractDataFromContent(content, scanConfig.baseUrl);
                        const hasNewData = addToScanResults(extractedData);
                        
                        // ğŸš€ update display å‡å°‘é¢‘ç‡ï¼ŒURL update item(s) time(s) æ¯20ä¸€
                        if (hasNewData && processedCount % 20 === 0) {
                            throttledUpdateDisplay();
                        }
                        
                        // URL collected æ–°
                        const discoveredUrls = await collectUrlsFromContent(content, scanConfig.baseUrl);
                        discoveredUrls.forEach(newUrl => newUrls.add(newUrl));
                    }
                } catch (error) {
                    console.error(`scan ${url} failed:`, error);
                    addLogEntry(`âŒ scan failed: ${url} - ${error.message}`, 'error');
                } finally {
                    processedCount++;
                    // ğŸš€ update å‡å°‘è¿›åº¦é¢‘ç‡ï¼ŒURL update item(s) time(s) æ¯10ä¸€
                    if (processedCount % 10 === 0 || processedCount === totalUrls) {
                        updateProgressDisplay(processedCount, totalUrls, `# ${depth} scan layer(s)`);
                    }
                    activeWorkers.delete(workerPromise);
                }
            })();
            
            activeWorkers.add(workerPromise);
            
            // ğŸš€ add delay æ§åˆ¶å¹¶å‘æ•°å¹¶
            if (activeWorkers.size >= maxConcurrency) {
                await Promise.race(Array.from(activeWorkers));
            }
            
            // ğŸš€ add delayï¼Œrequest é¿å…è¿‡å¿«
            if (i % maxConcurrency === 0 && i > 0) {
                await new Promise(resolve => setTimeout(resolve, 100)); // 100ms delay
            }
        }
    };
    
    await processQueue();
    
    // complete waiting all work
    if (activeWorkers.size > 0) {
        await Promise.all(Array.from(activeWorkers));
    }
    
    return Array.from(newUrls);
}

// function of å…¶ä»–å¿…è¦ï¼ˆversion ç®€åŒ–ï¼‰...
// contains function of è¿™é‡Œéœ€è¦å…¶ä»–å¿…è¦ï¼Œperformance optimization ä½†éƒ½ç»è¿‡

//console.log('âœ… deep scan script windowï¼ˆperformance optimization versionï¼‰complete load');